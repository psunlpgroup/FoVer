Verifier                                                                                   & GSM8K              & MATH               & AQuA-RAT           & AIME               & FOLIO              & LogicNLI           & ANLI               & HANS               & MMLU-Pro-NoMath    & Temporal           & Tracking           & Sorting            & Average \\
\midrule
w/o Best-of-K                                                                              & 85.2\phantom{$^*$} & 35.2\phantom{$^*$} & 57.1\phantom{$^*$} & 3.2\phantom{$^*$}  & 57.1\phantom{$^*$} & 36.4\phantom{$^*$} & 30.4\phantom{$^*$} & 74.8\phantom{$^*$} & 54.0\phantom{$^*$} & 87.2\phantom{$^*$} & 85.6\phantom{$^*$} & 36.4\phantom{$^*$} & 53.6\phantom{$^*$} \\
\midrule
Llama 3.1 8B                                                                               & 86.8\phantom{$^*$} & 42.4\phantom{$^*$} & 65.0\phantom{$^*$} & 3.2\phantom{$^*$}  & 57.6\phantom{$^*$} & 38.8\phantom{$^*$} & 27.2\phantom{$^*$} & 73.6\phantom{$^*$} & 56.4\phantom{$^*$} & 90.0\phantom{$^*$} & 90.0\phantom{$^*$} & 40.0\phantom{$^*$} & 55.9\phantom{$^*$} \\
\midrule
Llama 3.1 8B-FoVer (fldx2-symbol-multi-turn-balanced-last-step-20k-AdamW)                  & 88.4\phantom{$^*$} & 40.8\phantom{$^*$} & 69.7$^*$           & 4.4\phantom{$^*$}  & 65.5$^*$           & 43.6\phantom{$^*$} & 30.8$^*$           & 83.6$^*$           & 55.2\phantom{$^*$} & 89.2\phantom{$^*$} & 96.0$^*$           & 40.8\phantom{$^*$} & 59.0$^*$           \\
Llama 3.1 8B-FoVer (isabelle-all-multi-turn-balanced-last-step-20k-AdamW)                  & 89.2\phantom{$^*$} & 41.2\phantom{$^*$} & 70.1$^*$           & 2.0\phantom{$^*$}  & 61.1\phantom{$^*$} & 39.2\phantom{$^*$} & 28.8\phantom{$^*$} & 77.2\phantom{$^*$} & 55.6\phantom{$^*$} & 97.2$^*$           & 94.0$^*$           & 40.0\phantom{$^*$} & 58.0$^*$           \\
Llama 3.1 8B-FoVer (fldx2-symbol-isabelle-all-multi-turn-balanced-last-step-40k-AdamW)     & 86.4\phantom{$^*$} & 43.2\phantom{$^*$} & 65.7\phantom{$^*$} & 4.0\phantom{$^*$}  & 64.0$^*$           & 44.8$^*$           & 28.8\phantom{$^*$} & 82.8$^*$           & 57.2\phantom{$^*$} & 97.6$^*$           & 93.2$^*$           & 38.4\phantom{$^*$} & 58.8$^*$           \\
RLHFlow/Llama3.1-8B-PRM-Deepseek-Data                                                      & 91.6$^*$           & 46.8$^*$           & 67.7\phantom{$^*$} & 4.4\phantom{$^*$}  & 60.6\phantom{$^*$} & 39.6\phantom{$^*$} & 29.2\phantom{$^*$} & 76.0\phantom{$^*$} & 57.2\phantom{$^*$} & 98.8$^*$           & 92.0\phantom{$^*$} & 38.4\phantom{$^*$} & 58.5$^*$           \\
RLHFlow/Llama3.1-8B-PRM-Mistral-Data                                                       & 92.8$^*$           & 45.2\phantom{$^*$} & 64.6\phantom{$^*$} & 2.8\phantom{$^*$}  & 59.1\phantom{$^*$} & 44.0\phantom{$^*$} & 29.2\phantom{$^*$} & 79.2$^*$           & 54.0\phantom{$^*$} & 92.0\phantom{$^*$} & 91.2\phantom{$^*$} & 38.0\phantom{$^*$} & 57.7$^*$           \\
\midrule
Self-Consistency (Majority-of-K)                                                           & 89.2\phantom{$^*$} & 44.4\phantom{$^*$} & 66.1\phantom{$^*$} & 4.8\phantom{$^*$}  & 62.6\phantom{$^*$} & 46.0\phantom{$^*$} & 33.2\phantom{$^*$} & 76.4\phantom{$^*$} & 58.8\phantom{$^*$} & 92.8\phantom{$^*$} & 94.0\phantom{$^*$} & 42.4\phantom{$^*$} & 59.2\phantom{$^*$} \\
Oracle                                                                                     & 97.2\phantom{$^*$} & 58.4\phantom{$^*$} & 83.9\phantom{$^*$} & 8.8\phantom{$^*$}  & 90.1\phantom{$^*$} & 83.6\phantom{$^*$} & 54.4\phantom{$^*$} & 94.4\phantom{$^*$} & 75.2\phantom{$^*$} & 100.0\phantom{$^*$} & 98.4\phantom{$^*$} & 60.0\phantom{$^*$} & 75.4\phantom{$^*$} \\
