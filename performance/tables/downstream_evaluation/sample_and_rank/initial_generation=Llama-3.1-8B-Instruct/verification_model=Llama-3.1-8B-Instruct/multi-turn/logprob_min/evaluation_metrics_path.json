{
    "gsm8k": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/gsm8k/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/gsm8k/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/gsm8k/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/gsm8k/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/gsm8k/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/gsm8k/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/gsm8k/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/gsm8k/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/gsm8k/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "math": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/math/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/math/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/math/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/math/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/math/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/math/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/math/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/math/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/math/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "aqua": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/aqua/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/aqua/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/aqua/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/aqua/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/aqua/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/aqua/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/aqua/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/aqua/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/aqua/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "aime": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/aime/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/aime/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/aime/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/aime/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/aime/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/aime/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/aime/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/aime/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/aime/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "folio": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/folio/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/folio/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/folio/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/folio/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/folio/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/folio/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/folio/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/folio/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/folio/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "logicnli": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/logicnli/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/logicnli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/logicnli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/logicnli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/logicnli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/logicnli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/logicnli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/logicnli/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/logicnli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "anli": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/anli/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/anli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/anli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/anli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/anli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/anli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/anli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/anli/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/anli/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "hans": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/hans/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/hans/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/hans/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/hans/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/hans/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/hans/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/hans/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/hans/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/hans/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "mmlu_pro_nomath": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/mmlu_pro_nomath/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/mmlu_pro_nomath/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/mmlu_pro_nomath/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/mmlu_pro_nomath/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/mmlu_pro_nomath/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/mmlu_pro_nomath/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/mmlu_pro_nomath/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/mmlu_pro_nomath/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/mmlu_pro_nomath/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "bbh_temporal_sequences": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/bbh_temporal_sequences/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_temporal_sequences/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_temporal_sequences/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_temporal_sequences/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_temporal_sequences/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_temporal_sequences/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_temporal_sequences/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/bbh_temporal_sequences/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_temporal_sequences/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "bbh_tracking_shuffled_objects_three_objects": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/bbh_tracking_shuffled_objects_three_objects/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_tracking_shuffled_objects_three_objects/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_tracking_shuffled_objects_three_objects/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_tracking_shuffled_objects_three_objects/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_tracking_shuffled_objects_three_objects/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_tracking_shuffled_objects_three_objects/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_tracking_shuffled_objects_three_objects/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/bbh_tracking_shuffled_objects_three_objects/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_tracking_shuffled_objects_three_objects/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    },
    "bbh_word_sorting": {
        "base_model": "model_responses/downstream_evaluation/downstream_evaluation_initial_responses/bbh_word_sorting/few-shot/Llama-3.1-8B-Instruct/0/test.postprocessed.jsonl",
        "baseline_verifier": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_word_sorting/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_word_sorting/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol_multi_turn_balanced_last_step_20k_2.0e-6_0426/verification_score_type=logprob_min/test.jsonl",
        "fover_isabelle_all_multi_turn_balanced_last_step_20k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_word_sorting/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_isabelle_all_multi_turn_balanced_last_step_20k_1.0e-6_0429/verification_score_type=logprob_min/test.jsonl",
        "fover_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_AdamW": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_word_sorting/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama-3.1-8B-Instruct_fldx2_symbol-isabelle_all_multi_turn_balanced_last_step_40k_5.0e-6_0430/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Deepseek-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_word_sorting/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Deepseek-Data/verification_score_type=logprob_min/test.jsonl",
        "RLHFlow/Llama3.1-8B-PRM-Mistral-Data": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_word_sorting/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=Llama3.1-8B-PRM-Mistral-Data/verification_score_type=logprob_min/test.jsonl",
        "majority_vote": "model_responses/downstream_evaluation/majority_vote_output/bbh_word_sorting/few-shot/Llama-3.1-8B-Instruct/test.jsonl",
        "oracle": "model_responses/downstream_evaluation/best_sample_and_rank_output/bbh_word_sorting/multi-turn/base_model=Llama-3.1-8B-Instruct/verification_model=oracle/verification_score_type=logprob_min/test.jsonl"
    }
}